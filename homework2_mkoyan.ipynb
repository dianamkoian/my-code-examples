{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №2\n",
    "\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. ML workflow (**всего 5 баллов**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим данные для работы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"winequality-red.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем решать задачу регрессии: необходимо предсказать качество вина на основе его характеристик\n",
    "\n",
    "### Шаг 1.  (**0.2 балла**)\n",
    "Создайте матрицу X объект-признак и целевой вектор y (\"quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           float64\n",
       "volatile acidity        float64\n",
       "citric acid             float64\n",
       "residual sugar          float64\n",
       "chlorides               float64\n",
       "free sulfur dioxide     float64\n",
       "total sulfur dioxide    float64\n",
       "density                 float64\n",
       "pH                      float64\n",
       "sulphates               float64\n",
       "alcohol                 float64\n",
       "quality                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 2. (**0.2 балла**)\n",
    "Разбейте данные на train и test (доля тестовых данных - 30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 3. (**0.2 балла**)\n",
    "Обучите линейную регрессию на тренировочных данных и сделайте предсказания на train и на test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_reg = LinearRegression()\n",
    "l_reg.fit(X_train, y_train)\n",
    "y_pred_test = l_reg.predict(X_test)\n",
    "y_pred_train = l_reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 4. (**0.4 балла**)\n",
    "Выведите на экран ошибку MSE на train и на test, затем выведите на экран ошибку r2 на train и test.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE loss: \n",
      "mse_train=0.39116504963302506\n",
      "mse_test=0.48491526880549135\n",
      "R2_train=0.3676323607536507\n",
      "R2_test=0.3220437514697857\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''MSE loss: \n",
    "mse_train={mean_squared_error(y_train, y_pred_train)}\n",
    "mse_test={mean_squared_error(y_test, y_pred_test)}\n",
    "R2_train={r2_score(y_train,y_pred_train)}\n",
    "R2_test={r2_score(y_test, y_pred_test)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 5. (**0.5 балла**)\n",
    "Вычислите среднее качество (r2) модели на кросс-валидации с k=5 фолдами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cреднее качество (r2) =0.29004162884219614 \n"
     ]
    }
   ],
   "source": [
    "num_splits = 5\n",
    "r2_mean = cross_val_score(estimator=l_reg, X=X, y=y, cv=num_splits, scoring='r2').mean()\n",
    "print(f\"\"\"Cреднее качество (r2) ={r2_mean} \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 6.  (**0.5 балла**)\n",
    "Теперь примените линейную регрессию с L1-регуляризацией (Lasso) для данной задачи. Объявите модель и подберите параметр регуляризации alpha по сетке. Ищите alpha в диапазоне (0.1, 1.1) с шагом 0.1. \n",
    "\n",
    "Осуществите подбор параметра alpha по тренировочным данным (Xtrain, ytrain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1])}\n",
      "{'alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "n_alphas = 1.1/0.1\n",
    "alphas =  np.linspace(0.1, 1.1, n_alphas)\n",
    "params = {'alpha':alphas}\n",
    "print(params)\n",
    "cv = GridSearchCV(lasso,\n",
    "                  params,\n",
    "                  scoring='r2',\n",
    "                  cv=num_splits\n",
    "                 )\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 7.  (**0.5 балла**)\n",
    "Выведите наилучший алгоритм и наилучшее качество по результатам подбора alpha (best_estimator_ и best_score_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель - Lasso(alpha=0.1)\n",
      "Наилучшее качество 0.23086580138243312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "print(f'''Лучшая модель - {cv.best_estimator_}\n",
    "Наилучшее качество {cv.best_score_}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 8.  (**0.5 балла**)\n",
    "\n",
    "С помощью найденного best_estimator_ сделайте предсказание на тестовых данных и выведите на экран r2-score на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2-score на тесте: 0.20900374880379835\n"
     ]
    }
   ],
   "source": [
    "lasso_cv = Lasso(alpha=0.1)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "y_pred_t = lasso_cv.predict(X_test) #делаем предсказание\n",
    "R2_test_n= r2_score(y_test, y_pred_t)\n",
    "print('r2-score на тесте:', R2_test_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 9.  (**0.5 балла**)\n",
    "\n",
    "Попробуем улучшить качество модели за счет добавления полиномиальных признаков. Создайте pipeline, состоящий из добавления полиномиальных признаков степени 2, а затем применения линейной регрессии.\n",
    "\n",
    "Затем вычислите r2-score этой модели на кросс валидации с пятью фолдами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " r2-score модели c полиномиальными признаками : 0.2300961676836561 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "pipe = Pipeline([('polynomial', PolynomialFeatures(degree = 2)),('model_', LinearRegression())]) # pipeline, состоящий из добавления полиномиальных признаков степени 2\n",
    "r2_mean_pipe = cross_val_score(estimator=pipe, X=X, y=y, cv=num_splits, scoring='r2').mean()\n",
    "print(f\"\"\" r2-score модели c полиномиальными признаками : {r2_mean_pipe} \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 10.  (**0.5 балла**)\n",
    "Обучите модель (pipeline) на тренировочных данных и сделайте предсказания для train и test, затем выведите на экран r2-score и MSE на тренировочных и на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE loss: \n",
      "mse_train=0.44550776322765134\n",
      "mse_test=0.5742498128654916\n",
      "R2_train=0.27978051013889427\n",
      "R2_test=0.19714582341677445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train) #обучаем\n",
    "pipe_train = pipe.predict(X_train) #предсказание для  train \n",
    "pipe_test = pipe.predict(X_test) #предсказание для test\n",
    "print(f'''MSE loss: \n",
    "mse_train={mean_squared_error(y_train, pipe_train)}\n",
    "mse_test={mean_squared_error(y_test, pipe_test)}\n",
    "R2_train={r2_score(y_train,pipe_train)}\n",
    "R2_test={r2_score(y_test, pipe_test)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сделайте выводы. Для этого ответьте на вопросы: (**1 балл**)\n",
    "\n",
    "1) Хорошее ли качество показала исходная модель (линейная регрессия без регуляризации)? Является ли эта модель переобученной?\n",
    "\n",
    "2) Помогла ли L1-регуляризация улучшить качество модели?\n",
    "\n",
    "3) Помогло ли добавление полиномов второй степени улучшить качество модели? Как добавление новых признаков повлияло на переобучение?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Первая модель показала, что среднее качество (r2) =0.29, (R2_train=0.37, R2_test=0.32) , коэффициент детерминации небольшой, модель исходная модель не показала хорошее качество\n",
    "#### Модель является переобученной,  mse_train=0.39 существенно ниже, чем mse_test=0.48. Среднеквадратическая ошибка на тренировочных данных значительно больше, чем на тренировочных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Нет, r2-score на тестовых данных лишь ухудшился до 0.21 при  L1-регуляризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Добавление полиномов второй степени не помогло улучшить качество модели. Средний r2-score модели c полиномиальными признаками : 0.23 (R2_train=0.28, R2_test=0.2). \n",
    "#### Добавление новых признаков повлияло на переобучение лишь усилила проблему переобучения, увеличив разрыв между mse_train=0.45 и mse_test=0.57."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5657683082123666, 0.4685439959972928)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#дополнение ко второму пункту : проблема переобучения лишь усугубилась\n",
    "mean_squared_error(y_test, cv.predict(X_test)), mean_squared_error(y_train, cv.predict(X_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Попытайтесь улучшить модель (добейтесь наилучшего качества) - можно использовать любые методы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При улучшении качества r2 на 0.1-0.2 +1 балл, при большем улучшении +2 балла (дополнительно к 5 баллам за основную часть)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно немного улучшить качество, подобрав при L1-регуляризации alpha поменьше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "alphas_2 =  np.linspace(0.0001, 0.1, n_alphas)\n",
    "params_2 = {'alpha':alphas_2}\n",
    "cv_2 = GridSearchCV(lasso,\n",
    "                  params_2,\n",
    "                  scoring='r2',\n",
    "                  cv=num_splits\n",
    "                 )\n",
    "cv_2.fit(X_train, y_train)\n",
    "\n",
    "print(cv_2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель - Lasso(alpha=0.0001)\n",
      "Наилучшее качество 0.34405602912718425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''Лучшая модель - {cv_2.best_estimator_}\n",
    "Наилучшее качество {cv_2.best_score_}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2-score на тесте: 0.3206615804398373\n"
     ]
    }
   ],
   "source": [
    "lasso_cv_2 = Lasso(alpha=0.0001)\n",
    "lasso_cv_2.fit(X_train, y_train)\n",
    "y_pred_t_2 = lasso_cv_2.predict(X_test)\n",
    "R2_test_n_2= r2_score(y_test, y_pred_t_2)\n",
    "print('r2-score на тесте:', R2_test_n_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Target encoding (**всего 5 баллов**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом части домашнего задания вы будете работать с выборкой `1C`. Вам нужно посчитать счетчики для `item_id` четырьмя способами:\n",
    "\n",
    "    1) При помощи KFold схемы;  \n",
    "    2) При помощи Leave-one-out схемы;\n",
    "    3) При помощи smoothing схемы;\n",
    "    4) При помощи expanding mean схемы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>02.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>03.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>05.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>06.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2554</td>\n",
       "      <td>1709.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>15.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2555</td>\n",
       "      <td>1099.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2935844</td>\n",
       "      <td>10.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7409</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2935845</td>\n",
       "      <td>09.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2935846</td>\n",
       "      <td>14.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7459</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2935847</td>\n",
       "      <td>22.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7440</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2935848</td>\n",
       "      <td>03.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2935849 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  date_block_num  shop_id  item_id  item_price  target\n",
       "0        02.01.2013               0       59    22154      999.00     1.0\n",
       "1        03.01.2013               0       25     2552      899.00     1.0\n",
       "2        05.01.2013               0       25     2552      899.00    -1.0\n",
       "3        06.01.2013               0       25     2554     1709.05     1.0\n",
       "4        15.01.2013               0       25     2555     1099.00     1.0\n",
       "...             ...             ...      ...      ...         ...     ...\n",
       "2935844  10.10.2015              33       25     7409      299.00     1.0\n",
       "2935845  09.10.2015              33       25     7460      299.00     1.0\n",
       "2935846  14.10.2015              33       25     7459      349.00     1.0\n",
       "2935847  22.10.2015              33       25     7440      299.00     1.0\n",
       "2935848  03.10.2015              33       25     7460      299.00     1.0\n",
       "\n",
       "[2935849 rows x 6 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv('sales_train.csv.gz')\n",
    "sales.columns = ['date', 'date_block_num', 'shop_id', 'item_id', 'item_price', 'target']\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = [] \n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales[sales['date_block_num']==block_num]['shop_id'].unique()\n",
    "    cur_items = sales[sales['date_block_num']==block_num]['item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "#turn the grid into pandas dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\n",
    "#get aggregated values for (shop_id, item_id, month)\n",
    "gb = sales.groupby(index_cols,as_index=False).agg({'target':'sum'})\n",
    "\n",
    "#join aggregated data to the grid\n",
    "all_data = pd.merge(grid,gb,how='left',on=index_cols).fillna(0)\n",
    "#sort the data\n",
    "all_data.sort_values(['date_block_num','shop_id','item_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean encodings без регуляризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После проделанной технической работы, мы готовы посчитать счетчики для переменной `item_id`. \n",
    "\n",
    "Ниже приведены две реализации подсчета счетчиков без регуляризации. Можно использовать данный код в качестве стартовой точки для реализации различных техник регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Способ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4830386988621791\n"
     ]
    }
   ],
   "source": [
    "# Calculate a mapping: {item_id: target_mean}\n",
    "item_id_target_mean = all_data.groupby('item_id').target.mean()\n",
    "\n",
    "# In our non-regularized case we just *map* the computed means to the `item_id`'s\n",
    "all_data['item_target_enc'] = all_data['item_id'].map(item_id_target_mean)\n",
    "\n",
    "# Fill NaNs\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True) \n",
    "\n",
    "# Print correlation\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "print(np.corrcoef(all_data['target'].values, encoded_feature)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Способ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4830386988621791\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "     Differently to `.target.mean()` function `transform` \n",
    "   will return a dataframe with an index like in `all_data`.\n",
    "   Basically this single line of code is equivalent to the first two lines from of Method 1.\n",
    "'''\n",
    "all_data['item_target_enc'] = all_data.groupby('item_id')['target'].transform('mean')\n",
    "\n",
    "# Fill NaNs\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True) \n",
    "\n",
    "# Print correlation\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "print(np.corrcoef(all_data['target'].values, encoded_feature)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  KFold схема (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо реализовать Kfold схему с пятью фолдами. Используйте KFold(5) из sklearn.model_selection. \n",
    "\n",
    "1. Разбейте данные на 5 фолдов при помощи `sklearn.model_selection.KFold` с параметром `shuffle=False`.\n",
    "2. Проитерируйтесь по фолдам: используйте 4 обучающих фолда для подсчета средних значений таргета по `item_id` и заполните этими значениями валидационный фолд на каждой итерации.\n",
    "\n",
    "Обратите внимание на **Способ 1** из примера. В частности, изучите, как работают функции map и pd.Series.map. Они довольно полезны во многих ситуациях. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "num_splits = 5\n",
    "kf = KFold(shuffle=False, n_splits = num_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8731080 2182770\n",
      "8731080 2182770\n",
      "8731080 2182770\n",
      "8731080 2182770\n",
      "8731080 2182770\n"
     ]
    }
   ],
   "source": [
    "for train, test in kf.split(all_data):#получаем 4 обучающих фолда для подсчета\n",
    "    print(len(train), len(test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3343"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.loc[all_data.index[0],'item_target_enc'] #первая строка таблицы all_data, столбец item_target_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139255          NaN\n",
      "141495     0.048523\n",
      "144968     0.142424\n",
      "142661     0.030303\n",
      "138947     0.894020\n",
      "             ...   \n",
      "2215941    0.101779\n",
      "2213017    0.281195\n",
      "2211991    0.759582\n",
      "2212003    0.368177\n",
      "2217092    0.084211\n",
      "Name: item_target_enc, Length: 2182770, dtype: float64\n",
      "2213024    0.121429\n",
      "2218980    0.069149\n",
      "2217428    0.082090\n",
      "2218443    0.145602\n",
      "2214603    0.137529\n",
      "             ...   \n",
      "4473029    0.071599\n",
      "4480235    0.035842\n",
      "4474764    0.115473\n",
      "4473039    0.116844\n",
      "4479664    0.099559\n",
      "Name: item_target_enc, Length: 2182770, dtype: float64\n",
      "4479663    0.080552\n",
      "4479649    0.073384\n",
      "4479650    0.067134\n",
      "4479651    0.061060\n",
      "4477061    0.094551\n",
      "             ...   \n",
      "6704022    0.256080\n",
      "6704032    0.097826\n",
      "6704031    0.024390\n",
      "6701177    0.231568\n",
      "6704987    0.028681\n",
      "Name: item_target_enc, Length: 2182770, dtype: float64\n",
      "6701512    0.057534\n",
      "6701573    0.179245\n",
      "6704465    0.019417\n",
      "6704673    0.161538\n",
      "6701571    0.320620\n",
      "             ...   \n",
      "8510008    6.700997\n",
      "8508842    0.731047\n",
      "8510609    0.323308\n",
      "8508843    0.453405\n",
      "8513297    0.052288\n",
      "Name: item_target_enc, Length: 2182770, dtype: float64\n",
      "8513296     0.027304\n",
      "8513295     0.031646\n",
      "8510778     2.826790\n",
      "8508845     0.501295\n",
      "8512688     0.158983\n",
      "              ...   \n",
      "10768834    0.020000\n",
      "10769024         NaN\n",
      "10769690         NaN\n",
      "10771216    0.349227\n",
      "10770511    1.231425\n",
      "Name: item_target_enc, Length: 2182770, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for train, test in kf.split(all_data):\n",
    "    X_train = all_data.iloc[train] \n",
    "    X_train_target_mean  = X_train.groupby(\"item_id\").target.mean() #Calculate a mapping\n",
    "    all_data.loc[all_data.index[test],'item_target_enc'] = all_data.loc[all_data.index[test],'item_id'].map(X_train_target_mean)\n",
    "    #применение функции к каждому элементу итерируемого объекта в test\n",
    "    print(all_data.loc[all_data.index[test],'item_target_enc']) #проверяем, все ли работает так, как надо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41645907127988024\n"
     ]
    }
   ],
   "source": [
    "all_data['item_target_enc'].fillna(0.3343, inplace=True) #заполняем пропуски\n",
    "\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемый ответ 0.4165"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-one-out схема (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо реализовать leave-one-out схему . Учтите, если вы запустите код из первого задания, задав количество фолдов такое же как размер выборки, то вы, вероятно, получите правильный ответ, но ждать будете очень-очень долго.\n",
    "\n",
    "Для более быстрой реализации подсчета среднего таргета на всех объектах, кроме одного, вы можете:\n",
    "\n",
    "1. Вычислить суммарный таргет по всем объектам.\n",
    "2. Вычесть таргет конкретного объекта и разделить результат на `n_objects - 1`. \n",
    "\n",
    "Заметим, что пункт `1.` следует сделать для всех объектов. Также заметим, что пункт `2.` может быть реализован без циклов `for`.\n",
    "\n",
    "Здесь может оказаться полезной функция .transform из **Способа 2** из примера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139255         1.0\n",
       "141495        42.0\n",
       "144968        84.0\n",
       "142661        12.0\n",
       "138947      2092.0\n",
       "             ...  \n",
       "10768834     699.0\n",
       "10769024      75.0\n",
       "10769690     493.0\n",
       "10771216     348.0\n",
       "10770511    1320.0\n",
       "Name: item_id, Length: 10913850, dtype: float64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_target = all_data['item_id'].map(all_data.groupby('item_id')['target'].sum()) #суммарный таргет по всем объектам\n",
    "total_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.480384831129305\n"
     ]
    }
   ],
   "source": [
    "dif_target = (total_target - all_data['target']) #Вычитаем таргет конкретного объекта\n",
    "n_objects = all_data['item_id'].map(all_data.groupby('item_id')['target'].count()) #количество объектов\n",
    "all_data['item_target_enc'] = dif_target / (n_objects - 1) \n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемый ответ 0.4803"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо реализовать smoothing с $\\alpha = 100$. Используйте формулу:\n",
    "\n",
    "$\\frac{mean(target) \\cdot nrows + globalmean \\cdot \\alpha }{nrows + \\alpha}$,\n",
    "\n",
    "где $globalmean=0.3343$. Заметим, что `nrows` - это количество объектов, принадлежащих конктертной категории, а не количество строк в датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4818198797097282\n"
     ]
    }
   ],
   "source": [
    "alpha = 100\n",
    "globalmean = 0.3343\n",
    "\n",
    "mean_of_target = all_data.groupby('item_id')['target'].mean() #среднее таргета\n",
    "nrows = all_data.groupby('item_id')['target'].count() #количество объектов, принадлежащих конктертной категории,\n",
    "smoothing = (mean_of_target*nrows + globalmean*alpha) / (nrows + alpha) #формула\n",
    "all_data['item_target_enc'] = all_data['item_id'].map(smoothing) #применяем функцию\n",
    "\n",
    "#считаем корреляцию\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемый ответ 0.4818"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding mean схема (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо реализовать *expanding mean* схему. Ее суть заключается в том, чтобы пройти по отсортированному в определенном порядке датасету (датасет сортируется в самом начале задания) и для подсчета счетчика для строки $m$ использовать строки от $0$ до $m-1$. Вам будет необходимо воспользоваться pandas функциями [`cumsum`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.DataFrameGroupBy.cumsum.html) и [`cumcount`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.GroupBy.cumcount.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5025245211081701\n"
     ]
    }
   ],
   "source": [
    "cumulative_sum= all_data.groupby('item_id')['target'].cumsum() - all_data['target'] #кумулятивная сумма элементов \n",
    "cumulative_count= all_data.groupby('item_id').cumcount() #кумулятивный подсчет строк \n",
    "all_data['item_target_enc'] = cumulative_sum/cumulative_count # применяем схему expanding mean \n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True) # заполняем пропуски \n",
    "\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемый ответ 0.5025"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
